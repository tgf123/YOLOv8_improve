YOLOv12改进加QQ好友附上支付截图加群：3671595590,qq没有回复，可以直接添加微信 17329949407
YOLO12双backbone：https://github.com/tgf123/YOLOv8_improve/blob/master/YOLO12%E5%8F%8Cbackbone.md


<img src="https://github.com/tgf123/YOLOv8_improve/blob/master/11.jpg" width="210px">

整个改进目录：https://blog.csdn.net/qq_64693987/article/details/147497370

视频讲解：https://www.bilibili.com/video/BV17GPteVEzo?spm_id_from=333.788.videopod.sections&vd_source=8a6043a22d94a87da35299c073140577

本专栏为YOLOv12模型的魔改专栏，其中包含最新最有效的前沿论文的复现，我们将其中最有效的模块经过与C3K2 A2C2f Backbone head等相结合，对YOLOv12模型有效涨点。欢迎大家来订阅。

​
改进模块分类导航（持续更新）
1️⃣ Backbone结构优化
使用自适应稀疏自注意力ASSA修改Backbone部分，减少噪声，增强Backbone遮挡、小目标特征

在Backbone中添加卷积和注意力融合模块CAFM 利用注意力机制提取小目标和遮挡特征

在Backbone中添加级联组注意力机制CGA，解决Bacbone(cnn)特征丢失的问题

在Backbone中添加CMRF，利用其级联策略挖掘特征信息并融合不同感受野的信息，提高多尺度检测能力。

在Backbone中添加可变形交互注意力模块DIA-Module，提取全局上下文语义信息，增强上下文的联系。

在Backbone中添加深度启动和通道注意力模块DICAM，提高朦胧水下低图像的质量、对比度和色偏的目标。

在Backbone中添加双域条带注意力机制DSAM​，提取空间和频率域的高效特征聚合特征，提高小目标、多尺度、遮挡、噪声中的检测精度。

在Backbone中添加FFCM 应运而生，旨在通过融合频域特征，实现高效的全局建模,提高在噪声较多的背景中提高检测精度，同时增强边缘/纹理特征。

在backbone中使用傅里叶变换+Transformer模块FSAS模块，提取待检测物体的边缘，纹理特征（边缘模糊、或者需要边缘特征的部分）。

在backbone中添加HaloAttention注意力机制，增强多尺度特征，提取多尺度特征。

在Backbone中添加HSMSSD，过将通道混合操作从输入特征空间转移到压缩的隐状态空间，保持轻量化的同时，融合高低层特征，提升模型表示能力。

在backbone部分插入HTB，提取解决恶劣天气中待检测目标的特征。

在backbone部分插入多分支卷积IDC，提取多尺度特征。

在backbone部分插入曼哈顿自注意力机制Manhattan_SelfAttention，构建一种具有明确空间先验且能有效处理全局信息的通用视觉骨干网络，提取遮挡、小目标特征。

在backbone部分插入多维协作注意力MCAM，从通道、高度、宽度三个维度的协同建模，动态捕捉关键特征。

在backbone部分插入频率多尺度注意力MFMSAttentionBlock，从多尺度和多频率信息方面提取特征，提高多尺度、小目标。

添加混合结构模块MixStructure，融合多尺度特征与混合注意力机制，实现全局去噪与局部细节恢复的平衡，提高小目标检测能力，增强细节特征。

在backbone部分插入多尺度大核注意力MLKA，通过结合大核分解与多尺度学习提取多尺度特征。

利用MSAA对backbone的特征进行细化处理。通过空间和通道两个路径的操作，增强了空间和通道方面的特征信息，提取多尺度特征。

在nebackbonek部分插入量化脉冲驱动的自注意力机制MSAR，提高对小目标、遮挡的关注。

在backbone引入多尺度卷积注意力模块MSCAM，通过 CAB、SAB 和 MSCB 三个子模块协同工作，提取多尺度特征，增强对遮挡目标的关注。

在backbone部分插入多尺度前馈网络MSFN，增强backbone的多尺度特征提取能力。

引入非局部注意力机制Non_Local，通过在全局范围内捕捉特征图中所有位置的相互关系，提升模型性能，增强小目标、遮挡检测/

引入自集成注意力机制SEAM，通过多视角特征融合和一致性正则化来增强模型的鲁棒性和泛化能力，特别适用于处理遮挡问题和多尺度特征融合问题

在backbone部分插入单头自注意力SHSA，结合全局上下文信息，提高对遮挡、小目标关注。

在backbone部分插入稀疏自注意力机制Sparse_Self_Attention，解决YOLO11因自注意力机制Backbone过分关注语义信息的问题。

在Backbone部分插入混洗注意力模块SSAttention，旨在更好地聚合不同扫描方向得到的序列，充分利用互补信息，增强全局特征。

在Backbone部分插入令牌统计自注意力TSSA，通过对令牌特征二阶矩统计分析，精准聚焦目标区域，提高提高多尺度 遮挡。

2️⃣ mamba模块
融入 Mamba 架构：插入视觉状态空间模块 VSS Block 的硬核升级

融入 Mamba 架构：插入混合模块Hybrid Module 像素和补丁双层面进行交互学习，提升小目标 多尺度

融入 Mamba 架构：高效视觉状态空间模块 EVSS 模块，模糊图像清晰化与特征增强， 提升小目标 多尺度

mamba-引入视觉状态空间模块VSS Block 高效融合多尺度特征​ 提升复杂场景下目标定位精度与背景区分能力

融入 大 - 小卷积LS Convolution 捕获全局上下文与小核分支提取局部细节，提升目标检测中的多尺度

2️⃣ Backbone替换
引入MobileNetV4替换backbone，平衡精度与效率

引入Swin Transformer替换backbone，利用自注意力机制获取上下文信息

引入ShuffleNet v1替换backbone，实现轻量化

引入ShuffleNet v2替换backbone，实现轻量化

引入OverLoCK替换YOLO backbone 融合自上而下注意力机制，实现高效的长程依赖建模与局部细节捕捉，同时平衡计算复杂度与性能

引入TransXNet替换YOLO backbone 学习全局和局部动态信息，提高检测精度

引入基于星运算(element-wise multiplication)的高效神经网络模型StarNet替换backbone

使用MobileMamba替换YOLO backbone 提高检测精度

3️⃣ 特征融合改进 concat
引入跨尺度选择性融合模块CSFblock 解决不同分辨率特征融合的问题

引入动态特征融合DFF模块，通过动态机制在融合过程中选择重要特征，以解决上述现有技术在特征融合方面的不足。

EFC 模块通过增强层间特征相关性来优化特征融合。解决卷积神经网络特征提取时易出现特征消失问题，以及传统特征金字塔网络（FPN）的融合方法，如简单拼接或相加操作，无法充分利用多尺度融合优势，不同层特征相关性弱，融合后易产生冗余特征。

引入多尺度差异融合模块MDFM，解决不同尺度特征融合时的差异问题。

引入调制融合模块MFM 动态融合不同层的特征，增强检测精度

4️⃣ Neck部分改进
使用自适应稀疏自注意力ASSA修改Neck部分，减少噪声，提高neck层对遮挡、小目标的感知能力

在Neck中添加可变形交互注意力模块DIA-Module，增强模型对不同变化物体的关注能力。

将使用傅里叶变换+Transformer模块FSAS插入到neck部分，增强neck部分的边缘信息

在Neck中添加HaloAttention注意力机制，增强多尺度特征，能有效处理不同尺度对象，提升对多尺度目标的关注能力。

引入分层互补注意力混合器HRAMI，旨在弥补Neck层下采样特征导致的像素级信息损失，同时利用语义级信息，保持高效的层次结构，提高检测精度。

在neck部分插入HTB，利用动态范围直方图自注意力（DHSA）和双尺度门控前馈网络（DGFF）解决恶劣天气中待检测目标难的问题。

在neck部分插入曼哈顿自注意力机制Manhattan_SelfAttention提高对待检测目标的关注。

在neck部分插入频率多尺度注意力MFMSAttentionBlock，解决低分辨率特征图上采样到高分辨率时，容易导致信息损失问题。

在neck部分插入量化脉冲驱动的自注意力机制MSAR，提高对小目标、遮挡的关注。

neck部分插入单头自注意力SHSA，提高对遮挡、小目标关注。

在neck部分插入稀疏自注意力机制Sparse_Self_Attention，平衡对语义和非语义特征的提取，提高在目标定位任务中的表现 。

在neck部分插入混洗注意力模块SSAttention，旨在更好地聚合不同扫描方向得到的序列，充分利用互补信息，增强全局信息。

在neck部分插入令牌统计自注意力TSSA，通过对令牌特征二阶矩统计分析，精准聚焦目标区域，提高检测精度。

5️⃣ C3K2模块改进
使用AFE_Block修改C3K2模块，提高复杂场景中的检测精度

使用风车卷积APConv 修改C3K2模块，提升红外小目标的检测能力（其他小目标也可以）

在C3K2模块中添加卷积加法自注意力机制CASelf_Attention，使用全群信息缓解CNN带来的细节特征丢失的问题。

在C3K2模块中添加通道混合器 CGLU，利用门控机制提高复杂场景中的检测精度（小目标、遮挡、多尺度）

使用CMUNeXt改进C3K2模块，利用大核深度可分离卷积提取全局信息，同时保持轻量化，解决遮挡小目标问题。 

使用上下文引导模块ContextGuided改进C3K2，利用并行空洞卷积，提取全局和局部特征，提前高小目标/多尺度检测能力

利用卷积调制ConvMod改进C3K2，有着自注意力机制的能力，但比其更加轻量化，解决多尺度、小目标问题

使用通道压缩的自注意力机制CRA改进C3K2,提取全局信息，解决CNN特征丢失的问题

DCT（离散余弦变换）是一种将图像从像素域转换到频率域的数学方法，可分离出高频（细节纹理）和低频（整体结构）成分，提升待检测目标的定位模型对微观和宏观信息的捕捉能力。

在C3K2模块中添加DLKA_Attention模块，利用其可变形的大核设计，自适应地捕捉不同形状和尺寸的对象特征，适用于遮挡，形状各异的目标

在C3K2模块中添加双域条带注意力机制DSAM​，旨在通过空间和频率域的高效特征聚合提高小目标、多尺度、遮挡、噪声中的检测精度。

在C3K2模块引入轻量级深度神经网络的卷积核Dual，结合了组卷积（GroupConv）和异构卷积（HetConv）的优势降低参数量

在C3K2模块引入EGA模块是 LEGNet 中用于处理低质量遥感图像的核心模块，有效解决遥感图像中对比度低、边缘不连续和光照变化导致的特征模糊问题

引入高效多尺度注意力EMA_attention，提高多尺度，小目标检测能力。

focal_modulation_module 提高多尺度小目标检测能力

在C3K2模块中引入特征细化模块FRFN，逐层细化特征，增强了网络对局部和全局信息的捕捉能力。这种方法特别适用于需要多尺度特征、小目标、遮挡等任务。

引入门控瓶颈卷积GBC 关注目标抑制背景干扰，增强模型对裂缝形态信息的建模能力。

在C3K2模块中引入多分支卷积IDC，提取多尺度特征。

在C3K2模块中引入核选择融合注意力KSFA 增大感受野，提高多尺度 小目标检测能力

在C3K2模块引入局部特征嵌入全局特征提取模块LEGM 融合全局与局部特征解决多尺度、去噪、遮挡的问题

在C3K2模块引入LIA，利用局部重要性的注意力机制，抑制噪声，提高遮挡、小目标检测。

在C3K2模块中引入LLSKM（可学习局部显著核模块），借鉴 “中心减邻域” 原理，将传统显著核分解为可学习的卷积核与注意力增强的普通卷积，通过通道注意力机制动态调整参数，引导网络捕捉红外小目标的点、边缘等显著特征，提升检测敏感性与多尺度适应性。

在C3K2模块引入LSKA，利用分离卷积核实现轻量化，同时结合局部和全局信息，提高小目标、遮挡检测

在C3K2模块引入局部通道注意力机制MLCA，结合局部和全局特征的能力，有效增强了模型对重要信息的关注。

在C3K2模块引入多尺度大核注意力MLKA，通过结合大核分解与多尺度学习提升多尺度目标检测能力。

在C3K2模块引入MSBlock，提升多尺度，小目标。

在C3K2模块中引入多尺度前馈网络MSFN，从多个尺度特征中充分挖掘和利用图像中的多尺度特征，提高多尺度检测能力。

引入多尺度小波池化变压器MWPT 通过结合小波变换、多尺度池化以及门控机制等技术解决多尺度、小目标、边缘模糊等问题

引入前景注意力Outlook_atention，它能高效地将更细粒度的特征和上下文编码为 token，提升模型对小目标、遮挡的检测性能

引入基于部分卷积的前馈网络PCFN，通过部分卷积和跨通道交互的方式来加强特征表达

引入并行化补丁感知注意力模块PPA 提升小目标检测，解决红外小目标检测下采样信息丢失问题的模块

引入矩形自校准模块RCM，通过矩形自校准注意力机制和形状自校准捕捉全局上下文信息，并结合局部细节融合，提升模型对前景物体的建模能力和边界识别精度。

在C3K2模块中引入Restormer，从不同子空间捕捉特征间关系，计算注意力权重衡量元素重要性以聚合信息，捕捉长距离依赖关系；通过位置编码为模型提供元素位置信息，辅助检测小目标、遮挡。

在C3K2模块中引入SConv，通过空间重构单元（SRU）和通道重构单元（CRU）减少卷积神经网络中的空间和通道冗余，增强对这正以及小目标的检测能力

在C3K2模块中引入Shift_channel_mix，缓解信息损失和梯度错误问题

引入简单无参数注意力模块SimAM 提升小目标和遮挡检测

引入自调制特征聚合模块SMFA，捕获非局部信息和局部细节，协同建模图像的全局结构与局部细节。

在C3K2模块中引入空间带状注意力机制SSA，增强模型对空间信息处理能力。

添加StarNet星形卷积StarsBlock，通过星操作（element-wise multiplication）实现高维非线性特征映射。

引入空间池化模块StripPooling，通过条带池化在水平和垂直方向上捕捉长距离依赖关系，增强全局和局部特征表达。解决遮挡、小目标

在C3K2模块中引入前 k 稀疏注意力TKSA 动态选择重要区域，关注遮挡小目标区域，减少噪声的影响

在C3K2模块中引入小波卷积WaveletConv增加频域信息，有效解决模糊问题以及对边缘和细节高频成分的关注。

引入了小波卷积模块WTConv ，旨在扩大卷积的感受野并有效捕捉图像中的低频信息。其对多尺度问题和小目标问题上有很好的效果。

6️⃣ A2C2f模块改进
使用自适应稀疏自注意力ASSA替换A2C2F中的自注意力机制，减少噪声，提高对遮挡、小目标的检测能力

在A2C2F模块中添加卷积和注意力融合模块CAFM，提升小目标和遮挡检测

在A2C2F模块中添加卷积加法自注意力机制CASelf_Attention，使用全群信息缓解CNN带来的细节特征丢失的问题。

在A2C2F模块中添加通道混合器 CGLU，利用门控机制提高复杂场景中的检测精度

利用卷积调制ConvMod改进A2C2F，有着自注意力机制的能力，但比其更加轻量化，解决多尺度、小目标问题

使用通道压缩的自注意力机制CRA替换A2C2F中的自注意力机制，利用其查询和键的通道维度缩减为一维的能力，降低了自注意力的计算成本，实现轻量化。

在A2C2F模块中添加可变形交互注意力模块DIA-Module替换原有的注意力，增强空间信息表示，使 YOLOv11在复杂场景下对可变形目标的定位更精准。

在A2C2F模块中添加DLKA_Attention模块，利用其可变形的大核设计，自适应地捕捉不同形状和尺寸的对象特征，适用于遮挡，形状各异的目标

在A2C2F模块中引入特征细化模块FRFN，逐层细化特征，增强了网络对局部和全局信息的捕捉能力。这种方法特别适用于需要多尺度特征、小目标、遮挡等任务。

使用傅里叶变换+Transformer模块FSAS替换原有的自注意力机制，引入频域特征，增强边缘信息，解决图像模糊问题等。

使用HaloAttention换原有的自注意力机制，通过 Haloing 策略和分块操作减少计算量与内存占用，同时构建多尺度特征层次，能有效处理不同尺度对象，提升了模型对复杂视觉任务的适应性和准确性。

使用HTB替换A2C2F原有的自注意力机制，利用动态范围直方图自注意力（DHSA）和双尺度门控前馈网络（DGFF）解决恶劣天气中待检测目标难的问题。

在A2C2F模块中引入多分支卷积IDC，提取多尺度特征。

在A2C2F模块中引入核选择融合注意力KSFA 增大感受野，提高多尺度 小目标检测能力

在A2C2F模块中引入LLSKM（可学习局部显著核模块），借鉴 “中心减邻域” 原理，将传统显著核分解为可学习的卷积核与注意力增强的普通卷积，通过通道注意力机制动态调整参数，引导网络捕捉红外小目标的点、边缘等显著特征，提升检测敏感性与多尺度适应性。

在A2C2F模块引入LSKA，利用分离卷积核实现轻量化，同时结合局部和全局信息，提高小目标、遮挡检测。

使用曼哈顿自注意力机制Manhattan_SelfAttention替换A2C2F模块自注意力机制，解决窗口操作对用于自注意力的令牌进行分区，从而降低计算成本

使用多维协作注意力MCAM替换A2C2F模块自注意力机制，通过轻量化设计实现通道、高度、宽度三个维度的协同建模，抗背景干扰，增强多尺度、小目标。

使用频率多尺度注意力MFMSAttentionBlock替换A2C2F模块自注意力机制，使用频域和多尺度相结合的方法增强YOLOv11模型的小目标和多尺度特征提取。

在A2C2F模块引入合局部通道注意力机制MLCA，结合局部和全局特征的能力，有效增强了模型对重要信息的关注。

使用量化脉冲驱动的自注意力机制MSAR改进A2C2F模块，现轻量化自注意力机制，通过低比特量化权重和二进制脉冲信号显著降低模型参数量与计算能耗，平衡检测效率与精度。

使用多尺度前馈网络MSFN改进A2C2F模块，从多个尺度特征中充分挖掘和利用图像中的多尺度特征，提高多尺度检测能力。

使用单头自注意力SHSA替换A2C2F模块自注意力机制，输入通道的一部分上应用单头注意力来减少计算冗余，同时保留全局和局部信息的结合，从而提高了效率和准确性。

引入自调制特征聚合模块SMFA，捕获非局部信息和局部细节，协同建模图像的全局结构与局部细节。

使用稀疏自注意力机制Sparse_Self_Attention替换A2C2F模块自注意力机制，模型能够抑制对语义信息的关注，将更多的注意力放在提取非语义特征上。同时，由于只在张量块内计算，减少了大量不必要的计算，降低了模型的计算量，提高了运行效率。

使用混洗注意力模块SSAttention替换A2C2F模块自注意力机制，旨在更好地聚合不同扫描方向得到的序列，充分利用互补信息。

使用令牌统计自注意力TSSA替换A2C2F模块自注意力机制，通过高效注意力算子解决传统自注意力机制计算和内存复杂度随输入 token 数量呈二次方增长的问题，实现轻量化。

7️⃣ UpSample 改进
引入跨尺度选择性融合模块CSFblock 解决不同分辨率特征融合的问题

DySample是一种轻量高效的动态上采样方法，通过动态采样的方式实现上采样。解决传统的最近邻插值和双线性插值的上采样方法。

考虑到YOLO目标检测的neck对特征特征层上采用的时候的时候，会产生特征的丢失，同时增强模型的多尺度特征，本文将SAFM模块替换neck层的upsample()。

7️⃣ Conv改进
在处理复杂图像时，单一的频域信息可能不足以捕获所有重要细节。为了解决这个问题，我们可以结合小波变换（DWT）和卷积操作的Down_wt。

入轻量级深度神经网络的卷积核Dual，结合了组卷积（GroupConv）和异构卷积（HetConv）的优势降低参数量

引入dynamic_tanh优化模型提高精度

MDFF旨在减少上下文特征的损失，融合多分支上下文关系，增强网络提取特征区域的能力

引入RepBN增强卷积过程中的归一化问题

引入残差哈尔离散小波变换RHDWT 降噪、减少特征丢失，增强小目标和遮挡的检测能力
